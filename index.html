
<!DOCTYPE html>
<html lang="en">

<head>
    <title>Prasann Singhal ( प्रसन्न सिंघल )</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>


<body>
    <h1>Prasann Singhal  <br> प्रसन्न सिंघल </h1>
    <img id="pic" src="./pfp_cropped.jpeg">
    <div id="bio">

        <p>Undergraduate Student, Computer Science / Linguistics <br> The University of Texas at Austin</p>
        <p> <i class="fa fa-envelope"></i> prasanns [at] cs.utexas.edu &nbsp; 
            <a href="https://github.com/PrasannS"><i class="fa fa-github fa-clickable"></i> PrasannS</a> &nbsp; 
            <a href="https://twitter.com/prasann_singhal"><i class="fa fa-twitter fa-clickable"></i> prasann_singhal</a> &nbsp; 
            <a href="https://www.semanticscholar.org/author/Prasann-Singhal/2187681933"><i class="fa fa-clickable"></i> semantic scholar </a>
            <!--<a href="https://twitter.com/prasann_singhal"><i class="fa fa-twitter fa-clickable"></i> prasann_singhal</a></p>-->
        
        <p>Hi, I'm Prasann! I'm an incoming PhD student at UC Berkeley, where I'll work with <a href="https://www.sewonmin.com/">Sewon Min</a> and <a href="https://jsteinhardt.stat.berkeley.edu/">Jacob Steinhardt</a>. 
            As an undergrad, I was extremely fortunate to be introduced to research by the amazing <a href="https://www.cs.utexas.edu/~gdurrett/">Greg Durrett</a> at <a href="https://www.utexas.edu/">UT Austin</a> where I majored in CS and linguistics.
        </p>

        <p>My research focuses on Natural Language Processing and I'm broadly interested in better understanding how language models work.
            Recently, I've recently been curious about how properties of data affect what different learning algorithms learn, 
            but I've done work understanding and improving RLHF algorithms (particularly focused on reward modeling and things like online vs offline supervision),
            efficiency in decoding algorithms, and using explanations to predict large language model out-of-distribution robustness.
        </p>
        <p> Prior to research, I've also had the chance to participate in <a href="https://devpost.com/PrasannS">nearly 20 hackathons, </a> and made a lot of fun projects. </p>
        <p>
            I love meeting new people so free to send me an email if you'd like to chat about anything (e.g. related research, unrelated research, 
            just want to say hi)! Likewise, if you're a high-schooler or undergrad interested in research or grad school, 
            I'm always happy to give advice if you feel it'd be useful.
        </p>
    </div> 


    <!-- <div>
        <h2>Preprints</h2>
    </div> -->
    <div>
        <h2>Publications</h2>
        <div class="pub_div">
            <p>
                <span class="pub"> 
                    <a href="https://arxiv.org/abs/2505.13444"> ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models </a>
                </span>
            </p>  
            <p class="authors">  Liyan Tang, Grace Kim, Xinyu Zhao, Thom Lake, Wenxuan Ding, Fangcong Yin, <u>Prasann Singhal</u>, Manya Wadhwa, Zeyu Leo Liu, Zayne Sprague, Ramya Namuduri, Bodun Hu, Juan Diego Rodriguez, Puyuan Peng, Greg Durrett. <span class="conf">arxiv 2025.</span> </p>
            <p>
                <span class="pub"> <a href="https://arxiv.org/abs/2409.12183"> To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning </a>
                </span>
            </p>  
            <p class="authors"> Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, <u>Prasann Singhal</u>, Xinyu Zhao, Xi Ye, Kyle Mahowald, and Greg Durrett. <span class="conf">Proceedings of ICLR 2025.</span> </p>
           <p>
                <span class="pub"> <a href="http://arxiv.org/abs/2405.01511"> D2PO: Discriminator-Guided DPO with Response Evaluation Models </a>
                </span>
                <a class="exinfo" href="https://github.com/PrasannS/d2po"> code</a>
            </p>
            <p class="authors"> <u>Prasann Singhal</u>, Nathan Lambert, Scott Niekum, Tanya Goyal, and Greg Durrett. <span class="conf">Proceedings of COLM 2024.</span> </p>
            <p>
                <span class="pub"> <a href="https://arxiv.org/abs/2310.03716"> A Long Way to Go: Investigating Length Correlations in RLHF </a>
                </span>
                <a class="exinfo" href="https://github.com/PrasannS/rlhf-length-biases"> code</a>
            </p>  
            <p class="authors"> <u>Prasann Singhal</u>, Tanya Goyal, Jiacheng Xu, and Greg Durrett. <span class="conf">(Oral Spotlight) Proceedings of COLM 2024.</span> </p>
            <p>
                <span class="pub"> <a href="https://arxiv.org/abs/2306.00947"> EEL: Efficiently Encoding Lattices for Reranking </a>
                </span>
                <a class="exinfo" href="https://github.com/PrasannS/eel-reranking"> code</a>
            </p>  
            <p class="authors"> <u>Prasann Singhal</u>, Jiacheng Xu, Xi Ye, and Greg Durrett. <span class="conf">Proceedings of ACL 2023.</span> </p>
            <p>
                <span class="pub"> <a href="https://arxiv.org/abs/2210.06725"> Assessing Out-of-Domain Language Model Performance from Few Examples </a>
                </span>
            </p>  
            <p class="authors"> <u>Prasann Singhal*</u>, Jarad Forristal*, Xi Ye, and Greg Durrett. <span class="conf">Proceedings of EACL 2023.</span> </p>

            <p></p>
        </div>
        
    </div>
    
    <div>
        <h2>Invited Talks / News </h2>
        <p> [Dec. 2024] Won the 2025 <span class="pub"> <a href="https://cra.org/about/awards/outstanding-undergraduate-researcher-award/"> CRA Outstanding Undergraduate Researcher Award </a>
                </span> (awardee)! </p>
        <p> [Jul. 2024] A Long Way to Go in RLHF @ SEAL Reading Group, Scale AI </a> </p>
        <p> [Feb. 2024] A Long Way to Go in RLHF @ <a href="https://jessyli.com/courses/lin393"> UT Austin LIN 393 Seminar </a> </p>
        <p> [Nov. 2023] A Long Way to Go in RLHF @ <a href="https://ist-unbabel-seminars.github.io/index"> IST & Unbabel Seminar </a> </p>
    </div>
    
    <div>
        <h2>Experience</h2>
        <p> <b>Scale AI</b> Research Intern / Part-time Researcher. Summer-Fall 2024.</p>
        <p> <b>UT Austin TAUR Lab</b> Undergraduate Research Assistant, Natural Language Processing. Fall 2021-Present. </p>
    </div>
    
    <div>
        <h2>Service / Teaching</h2> 
        <p> CS 388 (NLP) TA (Fall 2024) </p>
        <p> UT Austin Directed Reading Program Mentor (Spring 2024) </p>
        <p> <b>Reviewer:</b> EMNLP (22), TMLR (25)</p>
        <p> Founder / Teacher - Katy HACK Initiative: I spent 3 years starting/running CS education programs in local elementary / junior high schools</p>
        <p> Volunteer Teacher - I spent a summer teaching English, Computer Fundamentals in a village in Gujarat </p>
    </div>



<footer>
    Last updated: 06/2025, thanks to <a href="https://www.cs.utexas.edu/~xiye/"> Xi Ye</a> for help with this site!
</footer>


</body></html>
